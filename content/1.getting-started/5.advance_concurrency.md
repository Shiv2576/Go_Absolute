---
title: Advance Concurrency in Go
description: Senior level concept of Concurrency in Go.
navigation:
  icon: i-lucide-code-xml
---


### Semaphores 

A Semaphore is a concurrency primitive that , Allows up to n concurrent operations and blocks additional callers until the permit is realeased.

There Two Type of Semaphores:

- Binary Semaphore -> mutex-like (1 permit)
- Counting Semaphore -> bounded concurrency (N permit)


#### Why Go needs Semaphore (Even with Goroutines)

Problem with unbounded Concurrency:

- Exhaust file descriptors

- Overwhelm DB / RPC providers

- Trigger rate limits

#### Canonical Go Semaphore : Buffered Channel

A Buffered Channel with capacity N:

- Sending into channel : acquiring a permit
- Recieving from channel : releasing a permit

```go
sem := make(chan struct{}{})
```

Why struct{}?

- Zero allocation
- Zero memory
- Expresses “signal only”


Minimal Semaphore Example :

```go 

func main() {
	sem :=  make (chan struct{} , 3)
	var wg sync.WaitGroup
	
	
	for i := 0 ; i < 10 ; i++ {
		wg.Add(1)
		
		
		go func(id int) {
			defer wg.Done()
			
			sem <- struct{}{}
			defer func() { <- sem}()
			
			fmt.Println("Working:", id)
			time.Sleep(time.Second)
			
		}(i)
	}
	
	wg.Wait()
}

```


### Context Cancellation

A Context is a signal that says : "Stop what are you doing - the result no longer matters".
it carries Cancellation signal , Deadline / Timeouts , Requests-scoped values.

without Context :
- Goroutine Leaks
- Wasted CPU
- Stuck RPCs
- DB Connections never released


How Context Cancellations Actually works ? 

```go
ctx.Done() <-chan struct{}
ctx.Error() 
```

Internally:
- Done() is a channel.
- Closing it Broadcast cancellation.


```go
package main

import (
	"context"
	"fmt"
	"sync"
	"time"
)

func RPC(ctx context.Context, id int, sem chan struct{}, wg *sync.WaitGroup) {

	defer wg.Done()

	select {
	case sem <- struct{}{}:
		fmt.Println("Slot Acquired: ", id)
	case <-ctx.Done():
		fmt.Println("Cancelled before acquiring slot:", id)
		return
	}

	defer func() {
		<-sem
		fmt.Println("Realeased Slot: ", id)
	}()

	select {
	case <-time.After(2 * time.Second):
		fmt.Println("RPC finished", id)
	case <-ctx.Done():
		fmt.Println("RPC cancelled mid-Flight", id)
	}

}

func main() {
	sem := make(chan struct{}, 2) // max 2 concurrent calls
	var wg sync.WaitGroup

	for i := 0; i < 5; i++ {
		wg.Add(1)

		// Each call has only 1 second to succeed
		ctx, cancel := context.WithTimeout(context.Background(), 1*time.Second)
		defer cancel()

		go RPC(ctx, i, sem, &wg)
	}

	wg.Wait()
	fmt.Println("All done")
}

```


### Graceful Shutdown

This means "Stop accepting new work , finish in-flight work , then exit."

#### How do you stop safely without losing work or corrupting state?

#### Naive Shutdown (Wrong)

```go
os.Exit(0)
```

Result:

- In-flight request Dropped
- DB writes Aborted
- Goroutines leaked
- Clients see errors


#### Graceful Shutdown in Go (Canonical Pattern)

```go
server := &http.Server(Addr : ":8080")

go func(){
	if err := server.ListenAndServe(); err != nil && err != http.ErrServerClosed {
		log.Fatal(err)
	}
}()

<-ctx.Done()

shutdownCtx, cancel := context.WithTimeout(context.Background() , 10*time.Second)
defer cancel()

server.Shutdown(shutdownCtx)
```

What happens Internally

1. Stop accepting new Connections
2. Wait for in-Flight Requests
3. Force-close after Timeout


Shutdown Ordering (Critical)

1. Stop accepting traffic
2. Cancel Contexts
3. Stop Background Workers
4. Flush Buffers
5. Close DB
6. Exit


### Rate Limiter Algorithms (Time Control)

It protects APIs, DBs , RPC Providers , DownStream services from Burst Behavior (Where large amount of request happens in small time) and its also controls Request per Second.


#### Token Bucket Rate Limiting Algorithm 

- Bucket Holds Tokens
- Tokens are added at Fix rate.
- Each Request consumes 1 token.
- if empty -> reject or wait.



#### Leaky Bucket Rate Limiting Algorithm

- Request enter Bucket
- Bucket leaks at constant rate
- Excess requests overflow -> Dropped


### Backpressure Strategies

1. Blocking (Hard Backpressure)

```go
sem <- struct{}{}
```

2. Bounded Queue (Preferred)

```go
jobs := make(chan Job, 100)
```

3. Reject-Fast (Load Shredding)

```go
select {
	case jobs <- job:
	default:
	return errors.New("Overloaded")
}
```
